version: '3.1'

services:
  jupyter:
    build:
      context: ./jupyter
      dockerfile: Dockerfile
      args:
        http_proxy:
        https_proxy:
        ftp_proxy:
        ALMOND_VERSION: 0.8.2
        SCALA_VERSIONS: 2.12.8
    image: ${DOCKER_NOTEBOOK_IMAGE}
    container_name: jupyter
    hostname: jupyter
    ports:
      - "4040:4040"
      - "10000:8888"
    environment:
      - JUPYTER_ENABLE_LAB=yes 
      - PASSWORD=marcos
    volumes:
      - C:/Users/marco/√Årea de Trabalho/courses:/home/marcos/work

  spark-master:
    build:
      context: ./spark-master
      dockerfile: Dockerfile
      args:
        http_proxy:
        https_proxy:
        ftp_proxy:
    image: spark-master:spark3.5.0-hadoop3-java8
    container_name: spark-master
    hostname: spark-master
    ports:
      - "8585:8080"
      - "7077:7077"
    volumes:
      - ${APPS_VOLUME_SPARK}:/opt/spark-apps
      - ${DATA_VOLUME_SPARK}:/opt/spark-data
            
  spark-worker-1:
    build:
      context: ./spark-worker
      dockerfile: Dockerfile
      args:
        http_proxy:
        https_proxy:
        ftp_proxy:
    image: spark-worker:spark3.5.0-hadoop3-java8
    container_name: spark-worker-1
    hostname: spark-worker-1
    depends_on:
      - spark-master
    ports:
      - "8081:8081"
    volumes:
       - ${APPS_VOLUME_SPARK}:/opt/spark-apps
       - ${DATA_VOLUME_SPARK}:/opt/spark-data

  spark-worker-2:
    image: spark-worker:spark3.5.0-hadoop3-java8
    container_name: spark-worker-2
    hostname: spark-worker-2
    depends_on:
      - spark-master
    ports:
      - "8082:8081"
    volumes:
       - ${APPS_VOLUME_SPARK}:/opt/spark-apps
       - ${DATA_VOLUME_SPARK}:/opt/spark-data

  namenode:
    image: hadoop-namenode:hadoop3.3.6-java8
    container_name: namenode
    build:
      context: ./namenode
      dockerfile: Dockerfile
      args:
        http_proxy:
        https_proxy:
        ftp_proxy:
    volumes:
      - "namenode:/hadoop/dfs/name"
    environment:
      - CLUSTER_NAME=test
    env_file:
      - .env    
    ports:
      - 9870:9870
      - 9000:9000  
      - 50070:50070

  datanode-1:
    image: hadoop-datanode:hadoop3.3.6-java8
    build:
      context: ./datanode
      dockerfile: Dockerfile
      args:
        http_proxy:
        https_proxy:
        ftp_proxy:
    container_name: datanode-1
    depends_on:
      - namenode
    volumes:
      - "datanode-1:/hadoop/dfs/data"
    env_file:
      - .env    
    ports:
      - 9871:9864
      - 50071:50075

  datanode-2:
    image: hadoop-datanode:hadoop3.3.6-java8
    build:
      context: ./datanode
      dockerfile: Dockerfile
      args:
        http_proxy:
        https_proxy:
        ftp_proxy:
    container_name: datanode-2
    depends_on:
      - namenode
    volumes:
      - "datanode-2:/hadoop/dfs/data"
    env_file:
      - .env    
    ports:
      - 9872:9864
      - 50072:50075

  resourcemanager:
    build:
      context: ./resourcemanager
      dockerfile: Dockerfile
      args:
        http_proxy:
        https_proxy:
        ftp_proxy:
    depends_on:
      - namenode
    image: hadoop-resourcemanager:hadoop3.3.6-java8
    container_name: resourcemanager
    environment:
      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode-1:9864 datanode-2:9864"
    env_file:
      - .env
    ports:
      - 8088:8088
  
  nodemanager1:
    image: hadoop-nodemanager:hadoop3.3.6-java8
    build:
      context: ./nodemanager
      dockerfile: Dockerfile
      args:
        http_proxy:
        https_proxy:
        ftp_proxy:
    container_name: nodemanager
    restart: always
    environment:
      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode-1:9864 datanode-2:9864 resourcemanager:8088"
    env_file:
      - .env

  historyserver:
    image: hadoop-historyserver:hadoop3.3.6-java8
    build:
      context: ./historyserver
      dockerfile: Dockerfile
      args:
        http_proxy:
        https_proxy:
        ftp_proxy:
    container_name: historyserver
    restart: always
    environment:
      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode-1:9864 datanode-2:9864 resourcemanager:8088"
    volumes:
      - hadoop_historyserver:/hadoop/yarn/timeline
    env_file:
      - .env

volumes:
  datanode-1:
  datanode-2:
  namenode:
  spark-apps:
  spark-data:
  jupyter-work:
  hadoop_historyserver:

networks:
  default:
    external:
      name: ${DOCKER_NETWORK_NAME}
